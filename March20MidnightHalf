import pandas as pd
import random
import numpy as np
import math

def main():
    print('Welcome to Alex Nguyen\'s Feature Selection Algorithm.')
    print('Type in the name of the file to test: ')
    print('')
    print('Type in the name of the algorithm you want to run.')
    print('')
    print('\t1) Forward Selection\n\t2) Backwards Elimination\n\t3) Alex\'s Special Algorithm')
    print('')
    print('\t\t\t1')
    print('')
    print('This dataset has %d features (not including the class attribute), with %d instances' % (10, 100))

#   \s is spaces. \s+ is at least one space
df = pd.read_csv('CS205_SMALLtestdata__68.txt', sep = '\s+', names=['Class Label',
        '1', '2', '3', '4', '5', '6',
        '7', '8', '9', '10'])
#   The head method displays the first five rows
print(df.head())
print('\n', end='')
print(df.columns)
#   Shows some statistics about the data frame, such as count
#print(df.describe())

num_rows = df.shape[0]
print("Number of rows: %d" % num_rows)
num_cols = df.shape[1]
print('Number of columns: %d' % num_cols)

'''
    Nearest Neighbor Algorithm
        Inputs:     - One row for the test set
                    - One (or many rows) for the training set
                    - A list that holds the names of the columns (e.g. 'Class Label')
        Process:    Do Euclidean Distance between all data points. Use a loop
                    Find the smallest distance. Make that the label of our node for that feature. Either correct or not
                    Then change test set. Repeat
        Output:     The Euclidean Distance
'''
def nearest_neighbor(test, train, feature, bitmap, test_row):

    num_correct = 0     #Number of correct labels
    bsf_dist = np.inf
    classs = 0
    #neighbor = 0

    #   Loop through the training list
    for i in range (0, train.shape[0]+1):
        dist = 0
        #   This is good. Don't second-guess yourself
        #   It's job is to nullify all features that are not used and calculate all
        #       features that are used between a test point and one training point
        if i != test_row:
            for j in range(0, 10):
                dist = dist + bitmap[0][j] * ((float(test[feature[j+1]]) -
                    float(train.loc[i:i][feature[j+1]]))**2)
            dist = np.sqrt(dist)
            #print(dist)
            if (dist < bsf_dist):
                bsf_dist = dist
                #neighbor = train.loc[i:i]
                #print('Neighbor:\n', neighbor)
                classs = train.loc[i:i][feature[0]]
    #print('Smallest distance: ', bsf_dist)
    #print('Predicted Class: ', classs.item())
    #print('Neighbor:\n', neighbor)

    #if classs.item() == 1:
    #    print("HI\n")

    # dist = ((float(test[feature[1]]) - float(train[feature[1]]))**2)**(0.5)
    # %f gets floating points, while %d gets integers only
    #print("The Euclidean Distance: %f" % dist)
    return classs.item()

'''
    Leave-One-Out Cross Validation
        Inputs:     - Dataset
        Process:    - Use a loop to go through every row of the dataset. Put on point in the test set and
                        the rest in the training set
                    - Call Nearest Neighbor to find out the label of the test data point
        Output:     Returns the ACCURACY
'''
def leave_one_out_cross_validation(dataset, current_set, feature_to_add):
    #   Bitmap with 10 columns. Used to calculate Euclidean Distance
    bitmap = np.zeros((1, dataset.shape[1] - 1), dtype = float)
    print(bitmap)
    '''
        List of Feature Names
            features[1] = 'Feature1', features[0] = 'Class Label'
    '''

    features = dataset.columns
    num_correct = 0
    print(len(current_set))
    for a in range(0, len(current_set)):
        bitmap[0][int(current_set[a]) - 1] = 1
    bitmap[0][int(feature_to_add) - 1] = 1
    print(bitmap)

    #   Later, change it to
    #       for i in range(0,100):
    for i in range(0, 100):
        #   Leave one out split
        test_set = dataset.loc[i:i]
        #print('Test Set: \n', test_set)
        df1 = dataset.loc[0:(i-1)]
        df2 = dataset.loc[i+1:100]        # Should be dataset.loc[i+1, 100]
        training_set = pd.concat([df1,df2])
        #print(test_set)
        #print(training_set)
        #print("Printing training set\n")
        #print(training_set)
        #print(training_set.loc[j:j])
        if nearest_neighbor(test_set, training_set, features, bitmap, i)\
                == test_set[features[0]].item():
            num_correct += 1
            #print("YES\n")
    print("NUMBER CORRECT: ", num_correct)
    print('Accuracy of Feature: ', num_correct / 100)

    return (num_correct / 100)

#curr = []
#leave_one_out_cross_validation(df, curr, '1')

'''
    Feature Search
        Start with no initial features
        Loop through the levels of the tree (size is number of features)
        Make a bsf accuracy
        Find the accuracy of a feature using the leave-one-out cross validation method
        It it's better than our bsf, update it
        Add the best feature to our current set of features
'''
def feature_search(data):

    #   Dictionaries are easier to search for membership
    current_features = {}
    current_features_list = []

    #   Iterating through the rows
    for i in range(0, 10):
        print('On level %d of search tree' % (i+1))
        best_so_far_accuracy = 0

        #   Iterating through the columns
        for j in range(0, data.shape[1] - 1):
            if not j in current_features:
                accuracy = leave_one_out_cross_validation(data, current_features_list, j + 1)
                print('\tUsing feature(s) {', end='')
                for bb in range(0, len(current_features_list)):
                    print('%d ' % bb, end='')
                    if (bb < len(current_features_list) - 1):
                        print(', ', end='')
                print('}, accuracy is %f%%' % accuracy)
                if accuracy > best_so_far_accuracy:
                    best_so_far_accuracy = accuracy
                    feature_to_add = j + 1
        #current_features.append(feature_to_add)
        current_features[feature_to_add] = ''
        current_features_list.append(feature_to_add)
        print('Added feature %d to the current set' % feature_to_add)
    print('\n', current_features, '\n')

print('Calling Feature Search\n')
feature_search(df)


if __name__ == "__main__":
    main()
